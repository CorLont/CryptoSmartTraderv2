6) Concrete fixes (incrementeel, met code)
6.1 Strict 80% gate – maak ‘m echt werkend
Vervang je orchestration/strict_gate.py door dit kleine, complete bestand:

python
Kopiëren
Bewerken
# orchestration/strict_gate.py
from __future__ import annotations
import pandas as pd
from dataclasses import dataclass

@dataclass
class GateResult:
    passed: pd.DataFrame
    total_candidates: int
    passed_count: int
    status: str  # "OK" | "EMPTY" | "INVALID"

def strict_toplist(pred_df: pd.DataFrame, pred_col="pred_720h", conf_col="conf_720h", thr=0.80) -> GateResult:
    if pred_df is None or pred_df.empty or pred_col not in pred_df or conf_col not in pred_df:
        return GateResult(pd.DataFrame(), 0, 0, "INVALID")
    df = pred_df.dropna(subset=[pred_col, conf_col]).copy()
    total = len(df)
    df = df[df[conf_col] >= thr].sort_values(pred_col, ascending=False)
    status = "EMPTY" if df.empty else "OK"
    return GateResult(df.reset_index(drop=True), total, len(df), status)

def apply_strict_gate_orchestration(all_preds: dict[str, pd.DataFrame], thr=0.80) -> dict:
    results = {h: strict_toplist(df, f"pred_{h}", f"conf_{h}", thr) for h, df in all_preds.items()}
    total = sum(r.total_candidates for r in results.values())
    passed = sum(r.passed_count for r in results.values())
    any_ok = any(r.status == "OK" for r in results.values())
    return {
        "gate_status": "OK" if any_ok else "EMPTY",
        "total_candidates": total,
        "total_passed": passed,
        "per_horizon": {h: r.passed for h, r in results.items()},
    }
6.2 Baseline ML – train & predict (zodat dashboards eindelijk echt data hebben)
Voeg deze minimale trainer toe (ml/train_baseline.py) die per horizon een RandomForest traint en ook uncertainty (ensemble‑spread) meegeeft:

python
Kopiëren
Bewerken
# ml/train_baseline.py
import pandas as pd, numpy as np, joblib, os
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import TimeSeriesSplit

HORIZONS = {"1h": "target_1h", "24h":"target_24h", "168h":"target_168h", "720h":"target_720h"}

def train_one(df: pd.DataFrame, target_col: str, features: list[str], n_models=5):
    tscv = TimeSeriesSplit(n_splits=5)
    models=[]
    X, y = df[features].values, df[target_col].values
    for seed in range(n_models):
        m = RandomForestRegressor(
            n_estimators=400, max_depth=None, random_state=seed, n_jobs=-1, oob_score=False
        )
        # laatste split als validatie, de rest voor training
        train_idx, test_idx = list(tscv.split(X))[-1]
        m.fit(X[train_idx], y[train_idx])
        models.append(m)
    return models

if __name__ == "__main__":
    feats = pd.read_parquet("exports/features.parquet")  # moet bestaan
    features = [c for c in feats.columns if c.startswith("feat_")]
    os.makedirs("models/saved", exist_ok=True)
    for h, tgt in HORIZONS.items():
        models = train_one(feats.dropna(subset=features+[tgt]), tgt, features)
        joblib.dump(models, f"models/saved/rf_{h}.pkl")
        print(f"Saved models/saved/rf_{h}.pkl ({len(models)} members)")
En een predictor (ml/models/predict.py) die per horizon pred_* en conf_* (1/(1+std)) uitspuugt:

python
Kopiëren
Bewerken
# ml/models/predict.py
import pandas as pd, numpy as np, joblib, glob

HORIZONS = ["1h","24h","168h","720h"]

def load_models():
    return {h: joblib.load(f"models/saved/rf_{h}.pkl") for h in HORIZONS if glob.glob(f"models/saved/rf_{h}.pkl")}

def predict_all(features_df: pd.DataFrame) -> pd.DataFrame:
    models = load_models()
    out = features_df[["coin","timestamp"]].copy()
    X = features_df[[c for c in features_df if c.startswith("feat_")]].values
    for h, ensemble in models.items():
        preds = np.column_stack([m.predict(X) for m in ensemble])
        mu = preds.mean(axis=1)
        sigma = preds.std(axis=1) + 1e-9
        out[f"pred_{h}"] = mu
        out[f"conf_{h}"] = 1.0 / (1.0 + sigma)  # 0..1, hoger = zekerder
    return out
Hiermee kun je binnen vandaag modellen trainen en de dashboards voeden (ook al is dit slechts een baseline zonder deep learning).

6.3 Sentiment – veilige fallback + calibratie‑haak
Maak een werkend sentimentmodel dat later FinBERT/LLM kan vervangen:

python
Kopiëren
Bewerken
# agents/sentiment/model.py (compacte, robuuste versie)
from dataclasses import dataclass
from typing import List, Dict, Optional
import numpy as np

@dataclass
class SentimentOutput:
    score: float   # -1..1
    prob_pos: float  # 0..1 (gecalibreerd later)
    sarcasm: float

class SentimentModel:
    def __init__(self, use_llm: bool=False):
        self.use_llm = use_llm  # hook voor OpenAI later

    def _basic_score(self, text: str) -> float:
        # super simpel, maar deterministic fallback
        text = (text or "").lower()
        pos = sum(w in text for w in ["bull", "pump", "moon", "good", "up", "win"])
        neg = sum(w in text for w in ["bear", "dump", "bad", "down", "rug", "loss"])
        return np.tanh((pos - neg) / 3)

    def predict_batch(self, texts: List[str]) -> List[SentimentOutput]:
        outs=[]
        for t in texts:
            s = float(self._basic_score(t))
            sarcasm = 0.0  # later: echte detector
            prob = 0.5 + 0.5*s  # ruwe proxy; calibratie gebeurt downstream
            outs.append(SentimentOutput(score=s, prob_pos=prob, sarcasm=sarcasm))
        return outs
6.4 Dashboard‑states koppelen aan realiteit
In je Streamlit app (tab “AI Voorspellingen” en “TOP KOOP KANSEN”), check:

python
Kopiëren
Bewerken
# pseudo in app.py
models_present = all(os.path.exists(f"models/saved/rf_{h}.pkl") for h in ["1h","24h","168h","720h"])
if not models_present:
    st.warning("⚠️ Geen getrainde modellen. Deze tab is uitgeschakeld.")
    st.stop()
En op de hoofdpagina: “System Online” → System Ready pas als:

models_present,

features.parquet < 24u oud,

calibration rapport OK,

health_score ≥ 85.

